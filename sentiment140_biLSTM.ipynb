{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q1nja3002K6d"
   },
   "source": [
    "# **NLP - Sentiment Analysis of Tweets using biLSTM**\n",
    "A deep learning model built using PyTorch and TorchText to classify sentiments of tweets using a subset of the <a href=\"https://www.kaggle.com/kazanova/sentiment140\">sentiment140 dataset</a>.\n",
    "\n",
    "1. [Dataset Preparation](#section1)\n",
    "2. [Preprocessing](#section2)\n",
    "3. [Model](#section3)\n",
    "4. [Training](#section4)\n",
    "5. [Prediction](#section5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YaKdyDBXxeK"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import spacy\n",
    "import random\n",
    "from pathlib import Path\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchtext import data \n",
    "import torchtext\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_subset = False # set to false if sentiment140-small-tokenized.csv already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "OFnqfIft6H-o",
    "outputId": "77aab575-7dd4-4535-b2d1-0bd5cfd46623"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Tesla K80\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Setting device on GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NddQVfQD37dO"
   },
   "source": [
    "<a id='section1'></a>\n",
    "# **1. Dataset Preparation**\n",
    "The first column contains the sentiments and the last column contains the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "nFyis9DPYpmg",
    "outputId": "2c58e9c9-034e-48dd-9089-5b65d7950ece"
   },
   "outputs": [],
   "source": [
    "if create_subset:\n",
    "    # Read in data into a dataframe\n",
    "    df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\", engine=\"python\", header=None)\n",
    "\n",
    "    df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YJ22CrBo4LEm"
   },
   "source": [
    "The dataset consists of two sentiments (0 - negative, 4 - positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "dl0IKQQMdtTR",
    "outputId": "dcfd8399-7026-4345-fd12-6024e00ac17e"
   },
   "outputs": [],
   "source": [
    "if create_subset:\n",
    "    # Count the number of tweets per sentiment\n",
    "    df[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "6CSfGCIF5Thr",
    "outputId": "b7412833-092d-4990-d7e5-e6d97a2319fa"
   },
   "outputs": [],
   "source": [
    "if create_subset:\n",
    "    # Model the sentiments as binary (0 - negative, 1 - positive)\n",
    "    df[0]=df[0].replace(to_replace=4,value=1)\n",
    "    df[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sentiment_util import tokenize_csv\n",
    "\n",
    "if create_subset:\n",
    "    # Save a subset as a smaller dataset from training\n",
    "    df.sample(500000).to_csv(\"sentiment140-small.csv\", header=None, index=None)\n",
    "    # remove stopwords, punctuation, and make everything lowercase\n",
    "    tokenize_csv('sentiment140-small.csv', 'sentiment140-small-tokenized.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sy5EFz2H8MqH"
   },
   "source": [
    "<a id='section2'></a>\n",
    "# **2. Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "eQT5JZvN8tB0",
    "outputId": "5d88197b-be9e-40c6-ec0a-526693d0c677"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchtext/data/utils.py:123: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(f'Spacy model \"{language}\" could not be loaded, trying \"{OLD_MODEL_SHORTCUTS[language]}\" instead')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train data: 399335\n",
      "Number of test data: 49917\n",
      "Number of validation data: 49917\n"
     ]
    }
   ],
   "source": [
    "# Declare fields for tweets and labels\n",
    "# include_lengths tells the RNN how long the actual sequences are\n",
    "TEXT = torchtext.legacy.data.Field(tokenize='spacy', lower=True, include_lengths= True)\n",
    "LABEL = torchtext.legacy.data.LabelField(dtype=torch.float)\n",
    "\n",
    "# Map data to fields\n",
    "fields = [('label', LABEL), ('text', TEXT)]\n",
    "\n",
    "# Apply field definition to create torch dataset\n",
    "dataset = torchtext.legacy.data.TabularDataset(\n",
    "        path=\"sentiment140-small-tokenized.csv\",\n",
    "        format=\"CSV\",\n",
    "        fields=fields,\n",
    "        skip_header=False)\n",
    "\n",
    "# Split data into train, test, validation sets\n",
    "(train_data, test_data, valid_data) = dataset.split(split_ratio=[0.8,0.1,0.1])\n",
    "\n",
    "print(\"Number of train data: {}\".format(len(train_data)))\n",
    "print(\"Number of test data: {}\".format(len(test_data)))\n",
    "print(\"Number of validation data: {}\".format(len(valid_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "mlZ9-mBFhw8L",
    "outputId": "bab39e21-7ed9-4125-d3a9-31c6bc94c5bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': '0', 'text': ['aw', 'hour', 'left', 'fun', 'weekend', 'fun', 'far', 'currently', 'reading', 'body', 'script']}\n"
     ]
    }
   ],
   "source": [
    "# An example from the training set\n",
    "print(vars(train_data.examples[10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TwbtK5lDlJj2"
   },
   "source": [
    "### **Build Vocabulary**\n",
    "Build the vocabulary for the training set using pre-trained GloVe embeddings.\n",
    "GloVe embeddings were trained on 6 billion tokens and the embeddings are 100-dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "fz_aN0Zl_Wwh",
    "outputId": "0202546b-fd25-4eb7-c76e-2bdeee054c6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 138768),\n",
       " ('day', 25038),\n",
       " ('good', 22465),\n",
       " ('get', 21319),\n",
       " ('like', 19745),\n",
       " ('go', 19442),\n",
       " ('got', 17400),\n",
       " ('love', 16768),\n",
       " ('work', 16663),\n",
       " ('today', 16156)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_VOCAB_SIZE = 287799\n",
    "\n",
    "# unk_init initializes words in the vocab using the Gaussian distribution\n",
    "TEXT.build_vocab(train_data, \n",
    "                 max_size = MAX_VOCAB_SIZE,\n",
    "                 vectors = \"glove.6B.100d\",\n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "# build vocab for training set - convert words into integers\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "# Most frequent tokens\n",
    "TEXT.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3d58JkuABB1d"
   },
   "source": [
    "### **Iterator**\n",
    "Pad each tweet to be the same length to process in batch. \n",
    "The BucketIterator will group tweets of similar lengths together for minimized padding in each batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HsrRy3dhAlSr"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "# sort_within_batch sorts all the tensors within a batch by their lengths\n",
    "train_iterator, valid_iterator, test_iterator = torchtext.legacy.data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    device = device,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key = lambda x: len(x.text),\n",
    "    sort_within_batch = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "braesWjckkJu"
   },
   "source": [
    "<a id='section3'></a>\n",
    "# **3. Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MAk1scwU_g3d"
   },
   "source": [
    "### **Create Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P6vpUuzkdCah"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/emilyjin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/emilyjin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentLSTM(\n",
      "  (embedding): Embedding(200867, 100, padding_idx=1)\n",
      "  (encoder): LSTM(100, 256, num_layers=2, dropout=0.5, bidirectional=True)\n",
      "  (predictor): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from models.sentiment_model import SentimentLSTM\n",
    "\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "# dim must be equal to the dim of pre-trained GloVe vectors\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "# 2 layers of biLSTM\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "# Dropout probability\n",
    "DROPOUT = 0.5\n",
    "# Get pad token index from vocab\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "# Create an instance of LSTM class\n",
    "model = SentimentLSTM(INPUT_DIM,\n",
    "            EMBEDDING_DIM,\n",
    "            HIDDEN_DIM,\n",
    "            OUTPUT_DIM,\n",
    "            N_LAYERS,\n",
    "            BIDIRECTIONAL,\n",
    "            DROPOUT,\n",
    "            PAD_IDX)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "TQ39qc-jv4PA",
    "outputId": "278e9670-ebbe-47bb-ee58-b5b8b0c09a4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': '0', 'text': ['aw', 'hour', 'left', 'fun', 'weekend', 'fun', 'far', 'currently', 'reading', 'body', 'script']}\n"
     ]
    }
   ],
   "source": [
    "# Sample from the training set\n",
    "print(vars(train_iterator.dataset[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2xPD99rLd5Fk",
    "outputId": "fddfa17d-bd08-4bab-d0e2-ff4a11d2ee1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200867, 100])\n"
     ]
    }
   ],
   "source": [
    "# Copy the pre-trained word embeddings into the embedding layer\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "# [vocab size, embedding dim]\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "We1MEJwZd9pp",
    "outputId": "a9e97fc7-d07c-4187-9cb1-97ec98e2639b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3073, -0.1130, -1.0766,  ...,  0.4044, -0.9157, -0.1943],\n",
       "        [-1.4156, -0.0118, -1.0315,  ..., -0.7681,  0.6292,  1.8166],\n",
       "        [-0.0465,  0.6197,  0.5665,  ..., -0.3762, -0.0325,  0.8062],\n",
       "        ...,\n",
       "        [ 0.1778, -0.7691, -0.0896,  ..., -1.8917, -0.4900,  0.6874],\n",
       "        [ 0.1090,  2.0768, -0.7294,  ...,  0.1431, -0.9128,  1.1328],\n",
       "        [-2.2512,  1.1518, -0.2669,  ...,  0.0503, -0.6633, -0.8909]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace the initial weights of the embedding layer with the pre-trained embeddings\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "p24pobL2eCqj",
    "outputId": "d48582e6-60c8-4147-c8d3-367d8093ffb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0465,  0.6197,  0.5665,  ..., -0.3762, -0.0325,  0.8062],\n",
      "        ...,\n",
      "        [ 0.1778, -0.7691, -0.0896,  ..., -1.8917, -0.4900,  0.6874],\n",
      "        [ 0.1090,  2.0768, -0.7294,  ...,  0.1431, -0.9128,  1.1328],\n",
      "        [-2.2512,  1.1518, -0.2669,  ...,  0.0503, -0.6633, -0.8909]])\n"
     ]
    }
   ],
   "source": [
    "# Initialize <unk> and <pad> both to all zeros - irrelevant for sentiment analysis\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "# Setting row in the embedding weights matrix to zero using the token index\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "print(model.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1FzS3q48u3bA"
   },
   "source": [
    "<a id='section4'></a>\n",
    "# **4. Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mp-WpuhLk1np"
   },
   "outputs": [],
   "source": [
    "# Adam optimizer used to update the weights\n",
    "# optimizer = optim.Adam(model.parameters(), lr=2e-3)\n",
    "\n",
    "# Loss function: binary cross entropy with logits\n",
    "# It restricts the predictions to a number between 0 and 1 using the logit function\n",
    "# then use the bound scarlar to calculate the loss using binary cross entropy\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Use GPU\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gsuG6zKbDk8t"
   },
   "source": [
    "### **Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sentiment_util import batch_accuracy, timer, evaluate, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "VxmPnZ6khFVP",
    "outputId": "851c8f5a-46c2-415f-a1cc-82484a31e6fb",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate is 0.001\n",
      "Epoch 1:\n",
      "\t Total Time: 1m 45s\n",
      "\t Train Loss 0.52 | Train Accuracy: 74.12%\n",
      "\t Validation Loss 0.47 | Validation Accuracy: 77.65%\n",
      "Epoch 2:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.47 | Train Accuracy: 77.76%\n",
      "\t Validation Loss 0.46 | Validation Accuracy: 78.37%\n",
      "Epoch 3:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.45 | Train Accuracy: 79.08%\n",
      "\t Validation Loss 0.45 | Validation Accuracy: 78.68%\n",
      "Epoch 4:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.43 | Train Accuracy: 80.21%\n",
      "\t Validation Loss 0.46 | Validation Accuracy: 78.22%\n",
      "Epoch 5:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.41 | Train Accuracy: 81.07%\n",
      "\t Validation Loss 0.46 | Validation Accuracy: 78.45%\n",
      "Epoch 6:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.4 | Train Accuracy: 81.92%\n",
      "\t Validation Loss 0.47 | Validation Accuracy: 77.51%\n",
      "Epoch 7:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.38 | Train Accuracy: 82.75%\n",
      "\t Validation Loss 0.47 | Validation Accuracy: 77.89%\n",
      "Epoch 8:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.37 | Train Accuracy: 83.48%\n",
      "\t Validation Loss 0.49 | Validation Accuracy: 77.58%\n",
      "Epoch 9:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.36 | Train Accuracy: 84.17%\n",
      "\t Validation Loss 0.49 | Validation Accuracy: 77.56%\n",
      "Epoch 10:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.35 | Train Accuracy: 84.72%\n",
      "\t Validation Loss 0.49 | Validation Accuracy: 77.67%\n",
      "learning rate is 0.005\n",
      "Epoch 1:\n",
      "\t Total Time: 1m 43s\n",
      "\t Train Loss 0.38 | Train Accuracy: 83.31%\n",
      "\t Validation Loss 0.51 | Validation Accuracy: 77.59%\n",
      "Epoch 2:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.36 | Train Accuracy: 84.29%\n",
      "\t Validation Loss 0.51 | Validation Accuracy: 77.03%\n",
      "Epoch 3:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.34 | Train Accuracy: 85.08%\n",
      "\t Validation Loss 0.54 | Validation Accuracy: 76.13%\n",
      "Epoch 4:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.33 | Train Accuracy: 85.57%\n",
      "\t Validation Loss 0.53 | Validation Accuracy: 76.41%\n",
      "Epoch 5:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.33 | Train Accuracy: 85.9%\n",
      "\t Validation Loss 0.53 | Validation Accuracy: 76.16%\n",
      "Epoch 6:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.32 | Train Accuracy: 86.12%\n",
      "\t Validation Loss 0.54 | Validation Accuracy: 75.62%\n",
      "Epoch 7:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.32 | Train Accuracy: 86.27%\n",
      "\t Validation Loss 0.57 | Validation Accuracy: 75.98%\n",
      "Epoch 8:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.32 | Train Accuracy: 86.39%\n",
      "\t Validation Loss 0.55 | Validation Accuracy: 75.86%\n",
      "Epoch 9:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.32 | Train Accuracy: 86.43%\n",
      "\t Validation Loss 0.58 | Validation Accuracy: 75.95%\n",
      "Epoch 10:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.32 | Train Accuracy: 86.51%\n",
      "\t Validation Loss 0.57 | Validation Accuracy: 75.55%\n",
      "learning rate is 0.01\n",
      "Epoch 1:\n",
      "\t Total Time: 1m 43s\n",
      "\t Train Loss 0.34 | Train Accuracy: 85.29%\n",
      "\t Validation Loss 0.56 | Validation Accuracy: 74.95%\n",
      "Epoch 2:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.37 | Train Accuracy: 83.59%\n",
      "\t Validation Loss 0.58 | Validation Accuracy: 74.55%\n",
      "Epoch 3:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.39 | Train Accuracy: 82.47%\n",
      "\t Validation Loss 0.58 | Validation Accuracy: 74.68%\n",
      "Epoch 4:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.41 | Train Accuracy: 81.67%\n",
      "\t Validation Loss 0.57 | Validation Accuracy: 73.34%\n",
      "Epoch 5:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.42 | Train Accuracy: 81.12%\n",
      "\t Validation Loss 0.58 | Validation Accuracy: 74.11%\n",
      "Epoch 6:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.43 | Train Accuracy: 80.56%\n",
      "\t Validation Loss 0.59 | Validation Accuracy: 74.09%\n",
      "Epoch 7:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.44 | Train Accuracy: 79.87%\n",
      "\t Validation Loss 0.56 | Validation Accuracy: 74.12%\n",
      "Epoch 8:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.45 | Train Accuracy: 79.38%\n",
      "\t Validation Loss 0.58 | Validation Accuracy: 72.65%\n",
      "Epoch 9:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.45 | Train Accuracy: 79.02%\n",
      "\t Validation Loss 0.57 | Validation Accuracy: 72.23%\n",
      "Epoch 10:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.46 | Train Accuracy: 78.61%\n",
      "\t Validation Loss 0.56 | Validation Accuracy: 73.72%\n",
      "learning rate is 0.05\n",
      "Epoch 1:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.82 | Train Accuracy: 57.34%\n",
      "\t Validation Loss 0.76 | Validation Accuracy: 53.61%\n",
      "Epoch 2:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.88 | Train Accuracy: 51.69%\n",
      "\t Validation Loss 0.76 | Validation Accuracy: 53.64%\n",
      "Epoch 3:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.89 | Train Accuracy: 51.23%\n",
      "\t Validation Loss 0.79 | Validation Accuracy: 51.59%\n",
      "Epoch 4:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.89 | Train Accuracy: 50.88%\n",
      "\t Validation Loss 0.79 | Validation Accuracy: 51.21%\n",
      "Epoch 5:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.89 | Train Accuracy: 50.77%\n",
      "\t Validation Loss 0.79 | Validation Accuracy: 51.84%\n",
      "Epoch 6:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.9 | Train Accuracy: 50.68%\n",
      "\t Validation Loss 0.78 | Validation Accuracy: 50.41%\n",
      "Epoch 7:\n",
      "\t Total Time: 1m 44s\n",
      "\t Train Loss 0.89 | Train Accuracy: 50.52%\n",
      "\t Validation Loss 0.8 | Validation Accuracy: 50.89%\n",
      "Epoch 8:\n",
      "\t Total Time: 1m 43s\n",
      "\t Train Loss 0.9 | Train Accuracy: 50.56%\n",
      "\t Validation Loss 0.8 | Validation Accuracy: 50.54%\n",
      "Epoch 9:\n",
      "\t Total Time: 1m 43s\n",
      "\t Train Loss 0.9 | Train Accuracy: 50.42%\n",
      "\t Validation Loss 0.78 | Validation Accuracy: 51.83%\n",
      "Epoch 10:\n",
      "\t Total Time: 1m 43s\n",
      "\t Train Loss 0.9 | Train Accuracy: 50.45%\n",
      "\t Validation Loss 0.8 | Validation Accuracy: 50.89%\n"
     ]
    }
   ],
   "source": [
    "# Number of epochs\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Lowest validation lost\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "learning_rates = [1e-3, 5e-3, 1e-2, 5e-2]\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f'learning rate is {lr}')\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Evaluate training loss and accuracy\n",
    "        train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "        # Evaluate validation loss and accuracy\n",
    "        valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        mins, secs = timer(start_time, end_time)\n",
    "\n",
    "        # At each epoch, if the validation loss is the best\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            # Save the parameters of the model\n",
    "            torch.save(model.state_dict(), 'model-small.pt')\n",
    "\n",
    "        print(\"Epoch {}:\".format(epoch+1))\n",
    "        print(\"\\t Total Time: {}m {}s\".format(mins, secs))\n",
    "        print(\"\\t Train Loss {} | Train Accuracy: {}%\".format(round(train_loss, 2), round(train_acc*100, 2)))\n",
    "        print(\"\\t Validation Loss {} | Validation Accuracy: {}%\".format(round(valid_loss, 2), round(valid_acc*100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WRHo-gVszo9H"
   },
   "source": [
    "<a id='section5'></a>\n",
    "# **5. Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sentiment_util import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "n40NoCEniiL6",
    "outputId": "5bfdc497-c2de-4f0c-d3fe-b722422fd4ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.45 | Test Acc: 78.91%\n"
     ]
    }
   ],
   "source": [
    "# Load the model with the best validation loss\n",
    "model.load_state_dict(torch.load('model-small.pt'))\n",
    "\n",
    "# Evaluate test loss and accuracy\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(\"Test Loss: {} | Test Acc: {}%\".format(round(test_loss, 2), round(test_acc*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "LNVfJSHooMus",
    "outputId": "9a7ccf8a-a352-4bf9-a025-1425d1e3761d"
   },
   "outputs": [],
   "source": [
    "# Single example prediction from the test set\n",
    "print(\"Tweet: {}\".format(TreebankWordDetokenizer().detokenize(test_data[100].text)))\n",
    "\n",
    "print(\"Prediction: {}\".format(round(predict(model, test_data[100].text), 2)))\n",
    "\n",
    "print(\"True Label: {}\".format(test_data[10].label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "8GD0zC4Fugk-",
    "outputId": "6f14da85-f61e-401e-fc07-d33533ec7250"
   },
   "outputs": [],
   "source": [
    "# Example prediction from the test set\n",
    "\n",
    "# List to append data to\n",
    "d = []\n",
    "\n",
    "\n",
    "for idx in range(10):\n",
    "\n",
    "    # Detokenize the tweets from the test set\n",
    "    tweet = TreebankWordDetokenizer().detokenize(test_data[idx].text)\n",
    "                                                 \n",
    "    # Append tweet, prediction, and true label\n",
    "    d.append({'Tweet': tweet, 'Prediction': predict(model, test_data[idx].text), 'True Label': test_data[idx].label})\n",
    "\n",
    "# Convert list to dataframe\n",
    "pd.DataFrame(d)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "sentiment140",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
