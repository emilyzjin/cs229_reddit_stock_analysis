{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python366jvsc74a57bd002820e647ccb6fa35f8f30dcdc1d9afda8f3817f309a398a968b8883ccf348a4",
   "display_name": "Python 3.6.6 64-bit ('cs229': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "02820e647ccb6fa35f8f30dcdc1d9afda8f3817f309a398a968b8883ccf348a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\timot\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "# This file gets OAuth tokens\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import praw\n",
    "import re\n",
    "from praw.models import MoreComments\n",
    "from tickers_names import *\n",
    "import yfinance as yf\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "import time\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'access_token': '-xtwAu2KI_1WrJjF6-XTstE6JFjEuXA', 'token_type': 'bearer', 'expires_in': 3600, 'scope': '*'}\n"
     ]
    }
   ],
   "source": [
    "# MAKE SURE TO PUT PASSWORD AND SECRET KEY IN SEPERATE FILE BEFORE MAKING REPO PUBLIC!!!\n",
    "\n",
    "\n",
    "CLIENT_ID = \"9whZ6oWY9qQBkA\"\n",
    "SECRET_KEY = \"v4JApa9eu1WvSTmy2eaoTmRHTQ33bw\"\n",
    "\n",
    "auth = requests.auth.HTTPBasicAuth(CLIENT_ID, SECRET_KEY)\n",
    "data = {'grant_type': 'client_credentials',\n",
    "        'username': 'CS229project',\n",
    "        'password': '229229'}\n",
    "headers = {'User-Agent': 'CS229project/0.0.1'}\n",
    "base_url = 'https://www.reddit.com/'\n",
    "res = requests.post(base_url + 'api/v1/access_token', auth=auth, data=data, headers=headers)\n",
    "# convert response to JSON and pull access_token value\n",
    "res_json = res.json()\n",
    "print(res_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id=CLIENT_ID, \n",
    "    client_secret=SECRET_KEY, \n",
    "    user_agent='CS229project/0.0.1',\n",
    "    username='CS229project',\n",
    "    password='229229')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TOKEN = res_json['access_token']\n",
    "# add authorization to our headers dictionary\n",
    "headers = {'User-Agent': 'CS229project/0.0.1', 'Authorization': f'bearer {TOKEN}', }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "reddit_data.csv file written\n"
     ]
    }
   ],
   "source": [
    "# general post data from r/wsb hot \n",
    "r = requests.get('https://oauth.reddit.com/r/wallstreetbets/hot', headers=headers)\n",
    "data = json.loads(r.text)['data']['children']\n",
    "\n",
    "with open('reddit_data.csv', 'w', encoding='utf8') as f:  \n",
    "    writer = csv.writer(f)\n",
    "    for dp in data:\n",
    "        for key, value in dp['data'].items(): \n",
    "            writer.writerow([key, value])\n",
    "print(\"reddit_data.csv file written\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'features': {'mod_service_mute_writes': True, 'promoted_trend_blanks': True, 'show_amp_link': True, 'mweb_in_feed_refresh': {'owner': 'growth', 'variant': 'random', 'experiment_id': 507}, 'is_email_permission_required': False, 'mod_awards': True, 'mweb_xpromo_revamp_v3': {'owner': 'growth', 'variant': 'treatment_1', 'experiment_id': 480}, 'chat_subreddit': True, 'awards_on_streams': True, 'mweb_xpromo_modal_listing_click_daily_dismissible_ios': True, 'modlog_copyright_removal': True, 'do_not_track': True, 'mod_service_mute_reads': True, 'chat_user_settings': True, 'use_pref_account_deployment': True, 'mweb_xpromo_interstitial_comments_ios': True, 'mweb_xpromo_modal_listing_click_daily_dismissible_android': True, 'premium_subscriptions_table': True, 'mweb_xpromo_interstitial_comments_android': True, 'mweb_footer_upsell': {'owner': 'growth', 'variant': 'light_1', 'experiment_id': 497}, 'chat_group_rollout': True, 'resized_styles_images': True, 'spez_modal': True, 'noreferrer_to_noopener': True, 'swap_steps_two_and_three_recalibration': {'owner': 'growth', 'variant': 'treatment_3', 'experiment_id': 324}, 'expensive_coins_package': True}}\n"
     ]
    }
   ],
   "source": [
    "# while the token is valid (~2 hours) we just add headers=headers to our requests\n",
    "res = requests.get('https://oauth.reddit.com/api/v1/me', headers=headers).json()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'features': {'mod_service_mute_writes': True,\n",
       "  'promoted_trend_blanks': True,\n",
       "  'show_amp_link': True,\n",
       "  'is_email_permission_required': False,\n",
       "  'mod_awards': True,\n",
       "  'expensive_coins_package': True,\n",
       "  'mweb_xpromo_revamp_v2': {'owner': 'growth',\n",
       "   'variant': 'treatment_4',\n",
       "   'experiment_id': 457},\n",
       "  'awards_on_streams': True,\n",
       "  'mweb_xpromo_modal_listing_click_daily_dismissible_ios': True,\n",
       "  'chat_subreddit': True,\n",
       "  'modlog_copyright_removal': True,\n",
       "  'do_not_track': True,\n",
       "  'mod_service_mute_reads': True,\n",
       "  'chat_user_settings': True,\n",
       "  'use_pref_account_deployment': True,\n",
       "  'mweb_xpromo_interstitial_comments_ios': True,\n",
       "  'mweb_xpromo_modal_listing_click_daily_dismissible_android': True,\n",
       "  'premium_subscriptions_table': True,\n",
       "  'mweb_xpromo_interstitial_comments_android': True,\n",
       "  'noreferrer_to_noopener': True,\n",
       "  'mweb_footer_upsell': {'owner': 'growth',\n",
       "   'variant': 'control_1',\n",
       "   'experiment_id': 497},\n",
       "  'chat_group_rollout': True,\n",
       "  'resized_styles_images': True,\n",
       "  'spez_modal': True,\n",
       "  'mweb_sharing_clipboard': {'owner': 'growth',\n",
       "   'variant': 'control_1',\n",
       "   'experiment_id': 315},\n",
       "  'swap_steps_two_and_three_recalibration': {'owner': 'growth',\n",
       "   'variant': 'treatment_7',\n",
       "   'experiment_id': 324}}}"
      ]
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "requests.get('https://oauth.reddit.com/api/v1/me', headers=headers).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('urls.csv', 'r', encoding='utf8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    urls = []\n",
    "    for row in reader:\n",
    "        urls.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-  RKT: No data found, symbol may be delisted\n",
      "-  RKT: No data found, symbol may be delisted\n",
      "- P: No data found for this date range, symbol may be delisted\n",
      "- MUH: No data found for this date range, symbol may be delisted\n",
      "- P: No data found for this date range, symbol may be delisted\n",
      "- COCO: No data found for this date range, symbol may be delisted\n",
      "- MIL: No data found for this date range, symbol may be delisted\n",
      "- MM: No data found for this date range, symbol may be delisted\n",
      "- LO: No data found for this date range, symbol may be delisted\n",
      "- P: No data found for this date range, symbol may be delisted\n",
      "- P: No data found for this date range, symbol may be delisted\n",
      "- HRS: No data found, symbol may be delisted\n",
      "- P: No data found for this date range, symbol may be delisted\n",
      "-  RKT: No data found, symbol may be delisted\n",
      "- P: No data found for this date range, symbol may be delisted\n",
      "- ATE: No data found, symbol may be delisted\n",
      "- ISH: No data found for this date range, symbol may be delisted\n",
      "-  RKT: No data found, symbol may be delisted\n",
      "- ISH: No data found for this date range, symbol may be delisted\n",
      "- P: No data found for this date range, symbol may be delisted\n",
      "- MIL: No data found for this date range, symbol may be delisted\n",
      "-  RKT: No data found, symbol may be delisted\n",
      "-  RKT: No data found, symbol may be delisted\n",
      "- P: No data found for this date range, symbol may be delisted\n",
      "- BORN: No data found, symbol may be delisted\n",
      "- BOI: No data found for this date range, symbol may be delisted\n",
      "- ATE: No data found, symbol may be delisted\n",
      "- P: No data found for this date range, symbol may be delisted\n",
      "- HF: No data found, symbol may be delisted\n",
      "-  RKT: No data found, symbol may be delisted\n",
      "-  RKT: No data found, symbol may be delisted\n",
      "- WAGE: No data found, symbol may be delisted\n",
      "- KITE: No data found for this date range, symbol may be delisted\n",
      "- P: No data found for this date range, symbol may be delisted\n",
      "- MIL: No data found for this date range, symbol may be delisted\n",
      "-  RKT: No data found, symbol may be delisted\n",
      "- P: No data found for this date range, symbol may be delisted\n",
      "may142021done,  data points written:  1547\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "Unexpected status code: 429",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-17f850b10596>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0murls\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mcomments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreddit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmission\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomments\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mcomments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace_more\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mt_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cs229\\lib\\site-packages\\praw\\models\\comment_forest.py\u001b[0m in \u001b[0;36mreplace_more\u001b[1;34m(self, limit, threshold)\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[0mnew_comments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m                 \u001b[0mremaining\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cs229\\lib\\site-packages\\praw\\models\\reddit\\more.py\u001b[0m in \u001b[0;36mcomments\u001b[1;34m(self, update)\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[1;34m\"sort\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmission\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomment_sort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m             }\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_comments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reddit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAPI_PATH\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"morechildren\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mcomment\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_comments\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cs229\\lib\\site-packages\\praw\\reddit.py\u001b[0m in \u001b[0;36mpost\u001b[1;34m(self, path, data, files, params, json)\u001b[0m\n\u001b[0;32m    756\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"POST\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m                 \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m             )\n\u001b[0;32m    760\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mRedditAPIException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cs229\\lib\\site-packages\\praw\\reddit.py\u001b[0m in \u001b[0;36m_objectify_request\u001b[1;34m(self, data, files, json, method, params, path)\u001b[0m\n\u001b[0;32m    670\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m                 \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m             )\n\u001b[0;32m    674\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cs229\\lib\\site-packages\\praw\\reddit.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, path, params, data, files, json)\u001b[0m\n\u001b[0;32m    853\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m                 \u001b[0mjson\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m             )\n\u001b[0;32m    857\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBadRequest\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cs229\\lib\\site-packages\\prawcore\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, path, data, files, json, params, timeout)\u001b[0m\n\u001b[0;32m    329\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m             \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m         )\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cs229\\lib\\site-packages\\prawcore\\sessions.py\u001b[0m in \u001b[0;36m_request_with_retries\u001b[1;34m(self, data, files, json, method, params, timeout, url, retry_strategy_state)\u001b[0m\n\u001b[0;32m    263\u001b[0m         assert (\n\u001b[0;32m    264\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSUCCESS_STATUSES\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m         ), f\"Unexpected status code: {response.status_code}\"\n\u001b[0m\u001b[0;32m    266\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"content-length\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"0\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Unexpected status code: 429"
     ]
    }
   ],
   "source": [
    "#urls = [\"https://www.reddit.com/r/wallstreetbets/comments/nm414o/daily_discussion_thread_for_may_27_2021/\"]\n",
    "for url in urls[1:70]:\n",
    "    comments = reddit.submission(url=url).comments\n",
    "    comments.replace_more(limit=32)\n",
    "    i = 0\n",
    "    t_list, t_dict = convert_data()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    add_words = ('one', 'all', 'fang', 'dd', 'elon', 'time', 'long', 'call', 'ever', 'see', 'gain', 'pm', 'rent', 'omg', 'baby', 'data', 'beat', 'win', 'tiny', 'tech', 'ago', 'type', 'bod', 'eod', 'man', 'else', 'true', 'save', 'away', 'min', 'max', 'news', 'n', 'look', 'news', 'beat', 'rent', 'good', 'pre', 'rate', 'club', 'hill', 'tax', 'fds', 'sale', 'per', 'full', 'ev', 'per', 'rice', 'men', 'king', 'post', 'well', 'town', 'r', 'cdc', 'su', 'af', 'line', 'dds', 'eat', 'well', 'free', 'nice', 'cool', 'plus', 'bit', 'bro', 'sale', 'date', 'mr', 'king', 'gg', 'pay', 'per', 'fish', 'flat', 'rate', 'semi', 'game', 'im', 'kang', 'act', 'via', 'avg', 'jfc', 'sir', 'lock', 'core', 'hear', 'fun', 'fast', 'big', 'rock', 'cash', 'air', 'gold', 'hr', 'car', 'trip', 'door', 'ape', 'hot', 'code', 'sons', 'fuel', 'mini', 'name', 'play', 'calm', 'two', 'jobs', 'glad', 'cost', 'tho', 'mo', 'luv', 'ship', 'fly', 'ppl', 'mind', 'cat', 'glad', 'zen', 'mark', 'blue', 'leaf', 'name', 'low', 'wood', 'jazz')\n",
    "    for word in add_words:\n",
    "        stop_words.add(word)\n",
    "    # comments.replace_more(limit=0)\n",
    "    url_date = url.split('/')[-2].split('_')\n",
    "    with open('reddit_data/reddit_data_' + url_date[-3] + url_date[-2] + url_date[-1] + '.csv', 'w', encoding='utf8') as f:  \n",
    "        writer = csv.writer(f)\n",
    "        for comment in comments:\n",
    "            #print(comment.body.lower())\n",
    "            # extract mentioned stocks\n",
    "            ticker_list = []\n",
    "            words = []\n",
    "            score = comment.score\n",
    "            for word in comment.body.lower().split():\n",
    "                words.append(\" \".join(re.findall(\"[a-zA-Z]+\", word)))\n",
    "            # print(\"####\\n\", words)\n",
    "            for word in words:\n",
    "                if (word not in ticker_list) and (word not in stop_words) and (word in t_list or (len(word) > 1 and word[0] == \"$\" and word[1:] in t_list)):\n",
    "                    ticker_list.append(word)\n",
    "                elif word in t_dict and t_dict[word] not in ticker_list and word not in stop_words:\n",
    "                    ticker_list.append(t_dict[word])\n",
    "            # get percent change, write rows\n",
    "            next_day = str(dt.fromtimestamp(comment.created_utc + 86400)).split()[0]\n",
    "            seven_days_back = str(dt.fromtimestamp(comment.created_utc - 86400 * 6)).split()[0]\n",
    "            seven_days_forward = str(dt.fromtimestamp(comment.created_utc + 86400 * 8)).split()[0]\n",
    "            for ticker in ticker_list:\n",
    "                try:  \n",
    "                    df = yf.Ticker(ticker).history(start=seven_days_back, end=seven_days_forward, interval=\"1d\")\n",
    "                    percent_change_back = df.iloc[4][3] / df.iloc[0][0]\n",
    "                    percent_change_forward = df.iloc[-1][3] / df.iloc[4][0]\n",
    "                    i += 1\n",
    "                    writer.writerow([words, ticker, score, percent_change_back, percent_change_forward])\n",
    "                except:\n",
    "                    pass\n",
    "            if i >= 1000:\n",
    "                break\n",
    "    print(url_date[-3] + url_date[-2] + url_date[-1] + \"done, \", \"data points written: \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "118\n"
     ]
    }
   ],
   "source": [
    "urls = [\"https://www.reddit.com/r/wallstreetbets/comments/nc4z12/daily_discussion_thread_for_may_14_2021/\"]\n",
    "for url in urls:\n",
    "    comments = reddit.submission(url=url).comments\n",
    "    print(comments[0].score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1620988034.0\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.reddit.com/r/wallstreetbets/comments/nc4z12/daily_discussion_thread_for_may_14_2021/\"\n",
    "comment = reddit.submission(url=url).comments[0]\n",
    "print(comment.created_utc)"
   ]
  }
 ]
}